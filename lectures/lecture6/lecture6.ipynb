{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3f03083",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Лекция 6\n",
    "\n",
    "# Решение систем линейных уравнений. LU разложение. Число обусловленности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd562fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## На прошлой лекции\n",
    "\n",
    "- Умножение матрицы на вектор (матвек)\n",
    "- Матричное умножение\n",
    "- Иерархия памяти\n",
    "- BLAS: структура и реализации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105e48c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## План на сегодня\n",
    "\n",
    "- Завершаем тему прошлой лекции\n",
    "    - Метод Штрассена и его сложность\n",
    "    - Связь методы Штрассена и тензорного разложения\n",
    "    - RL подход для получения новых алгоритмов матричного умножения\n",
    "- Линейные системы\n",
    "- (P)LU разложение\n",
    "- Устойчивость решения линейных систем и число обусловленности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb27241e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Улучшение алгоритмов матричного умножения\n",
    "\n",
    "- Наивная реализация $O(n^3)$\n",
    "- Можно ли сократить до $O(n^2)$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94962c3d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**A**: алгоритм умножения матриц со сложностью $\\mathcal{O}(n^2)$ до сих пор не найден."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b410c47f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Метод Штрассена – $\\mathcal{O}(n^{2.807\\dots})$, иногда используется на практике\n",
    "\n",
    "* [Текущий мировой рекорд](http://arxiv.org/pdf/1401.7714v1.pdf) $\\mathcal{O}(n^{2.37\\dots})$ – большая константа, не практичный, основан на [алгоритме Coppersmith-Winograd'a](https://en.wikipedia.org/wiki/Coppersmith%E2%80%93Winograd_algorithm).\n",
    "\n",
    "Рассмотрим метод Штрассена более детально."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd113541",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Наивный алгоритм\n",
    "\n",
    "Пусть $A$ и $B$ две матрицы $2\\times 2$. Наивное умножение $C = AB$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} c_{11} & c_{12} \\\\ c_{21} & c_{22}  \\end{bmatrix}  =\n",
    "\\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22}  \\end{bmatrix}\n",
    "\\begin{bmatrix} b_{11} & b_{12} \\\\ b_{21} & b_{22}  \\end{bmatrix} =\n",
    "\\begin{bmatrix} \n",
    "a_{11}b_{11} + a_{12}b_{21} & a_{11}b_{21} + a_{12}b_{22} \\\\ \n",
    "a_{21}b_{11} + a_{22}b_{21} & a_{21}b_{21} + a_{22}b_{22} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "состоит из $8$ умножений и $4$ сложений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6be1a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Алгоритм Штрассена\n",
    "\n",
    "В работе [Gaussian elimination is not optimal](http://link.springer.com/article/10.1007%2FBF02165411?LI=true) (1969 г.) Штрассен обнаружил, что можно вычислить матрицу $C$, используя 18 сложений и только 7 умножений:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "c_{11} &= f_1 + f_4 - f_5 + f_7, \\\\\n",
    "c_{12} &= f_3 + f_5, \\\\\n",
    "c_{21} &= f_2 + f_4, \\\\\n",
    "c_{22} &= f_1 - f_2 + f_3 + f_6,\n",
    "\\end{split}\n",
    "$$\n",
    "где\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "f_1 &= (a_{11} + a_{22}) (b_{11} + b_{22}), \\\\\n",
    "f_2 &= (a_{21} + a_{22}) b_{11}, \\\\\n",
    "f_3 &= a_{11} (b_{12} - b_{22}), \\\\\n",
    "f_4 &= a_{22} (b_{21} - b_{11}), \\\\\n",
    "f_5 &= (a_{11} + a_{12}) b_{22}, \\\\\n",
    "f_6 &= (a_{21} - a_{11}) (b_{11} + b_{12}), \\\\\n",
    "f_7 &= (a_{12} - a_{22}) (b_{21} + b_{22}).\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "К счастью, эти формулы работают даже если $a_{ij}$ и $b_{ij}$, $i,j=1,2$ – блочные матрицы.\n",
    "\n",
    "Таким образом, схема алгоритма Штрассена такова \n",
    "- Сначала мы  <font color='red'>разбиваем</font> матрицы $A$ и $B$ размера $n\\times n$, $n=2^d$ <font color='red'> на 4 блока</font> размера $\\frac{n}{2}\\times \\frac{n}{2}$\n",
    "- После чего <font color='red'>вычисляем произведения</font> по указанным выше формулам <font color='red'>рекурсивно</font>\n",
    "\n",
    "Это приводит нас к идее **разделяй и властвуй**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378096d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Сложность метода Штрассена\n",
    "\n",
    "#### Число умножений\n",
    "\n",
    "Обозначим $M(n)$ число умножений необходимых для вычисления произведения двух матриц $n\\times n$ с помощью стратегии \"разделяй и властвуй\".\n",
    "Тогда для наивного алгоритма получаем следующее число умножений\n",
    "\n",
    "$$\n",
    "M_\\text{naive}(n) = 8 M_\\text{naive}\\left(\\frac{n}{2} \\right) = 8^2 M_\\text{naive}\\left(\\frac{n}{4} \\right)\n",
    "= \\dots = 8^{d-1} M(1) = 8^{d} = 8^{\\log_2 n} = n^{\\log_2 8} = n^3\n",
    "$$\n",
    "\n",
    "Итак, даже используя стратегию \"разделяй и властвуй\" мы не улучшаем сложность в $\\mathcal{O}(n^3)$ операций.\n",
    "\n",
    "Вычислим число умножений в методе Штрассена:\n",
    "\n",
    "$$\n",
    "M_\\text{strassen}(n) = 7 M_\\text{strassen}\\left(\\frac{n}{2} \\right) = 7^2 M_\\text{strassen}\\left(\\frac{n}{4} \\right)\n",
    "= \\dots = 7^{d-1} M(1) = 7^{d} = 7^{\\log_2 n} = n^{\\log_2 7}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65464ec2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Число сложений\n",
    "\n",
    "Для алгоритма Штрассена:\n",
    "\n",
    "$$\n",
    "A_\\text{strassen}(n) = 7 A_\\text{strassen}\\left( \\frac{n}{2} \\right) + 18 \\left( \\frac{n}{2} \\right)^2\n",
    "$$\n",
    "поскольку на первом уровне нам нужно сложить матрицы размера $\\frac{n}{2}\\times \\frac{n}{2}$ 18 раз, а потом идти на следующий уровень рекурсии для каждого из 7 умножений. \n",
    "Таким образом,\n",
    "\n",
    "<font size=1.0>\n",
    "$$\n",
    "\\begin{split}\n",
    "A_\\text{strassen}(n) =& 7 A_\\text{strassen}\\left( \\frac{n}{2} \\right) + 18 \\left( \\frac{n}{2} \\right)^2 = 7 \\left(7 A_\\text{strassen}\\left( \\frac{n}{4} \\right) + 18 \\left( \\frac{n}{4} \\right)^2 \\right) + 18 \\left( \\frac{n}{2} \\right)^2 =\n",
    "7^2 A_\\text{strassen}\\left( \\frac{n}{4} \\right) + 7\\cdot 18 \\left( \\frac{n}{4} \\right)^2 +  18 \\left( \\frac{n}{2} \\right)^2 = \\\\\n",
    "=& \\dots = 18 \\sum_{k=1}^d 7^{k-1} \\left( \\frac{n}{2^k} \\right)^2 = \\frac{18}{4} n^2 \\sum_{k=1}^d \\left(\\frac{7}{4} \\right)^{k-1} = \\frac{18}{4} n^2 \\frac{\\left(\\frac{7}{4} \\right)^d - 1}{\\frac{7}{4} - 1} = 6 n^2 \\left( \\left(\\frac{7}{4} \\right)^d - 1\\right) \\leqslant 6 n^2 \\left(\\frac{7}{4} \\right)^d = 6 n^{\\log_2 7}\n",
    "\\end{split}\n",
    "$$\n",
    "</font>\n",
    "\n",
    "(так как $4^d = n^2$ и $7^d = n^{\\log_2 7}$).\n",
    "\n",
    "\n",
    "Асимптотику для $A(n)$ также можно найти с помощью следующей [теоремы](https://en.wikipedia.org/wiki/Master_theorem)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97905c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Итоговая сложность метода Штрассена\n",
    "\n",
    "Итоговая сложность –  $M_\\text{strassen}(n) + A_\\text{strassen}(n)=$ <font color='red'>$7 n^{\\log_2 7}$</font>. \n",
    "Метод Штрассена становится быстрее наивного алгоритма, если\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "2n^3 &> 7 n^{\\log_2 7}, \\\\\n",
    "n &> 667,\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "поэтому не самая хорошая идея спускаться на самый низкий уровень рекурсии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9807100",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Является ли метод Штрассена практически важным?\n",
    "\n",
    "- Долгое время считалось, что метод Штрассена имеет только теоретический интерес и плохо применим на практике\n",
    "- Статья [Strassen algorithm reloaded](http://jianyuhuang.com/papers/sc16.pdf)\n",
    "опровергает утверждение, что метод Штрассена не практичен, и предлагает реализацию, которая работает не только на больших матрицах.\n",
    "- Метод Штрассена научились \"выучивать\" с помощью нейросетей\n",
    "    - [V. Elser, 2016](https://www.jmlr.org/papers/volume17/16-074/16-074.pdf)\n",
    "    - [M. Tschanne et al, 2018](https://arxiv.org/pdf/1712.03942.pdf)\n",
    "    - [A. Fawzi, 2022](https://www.nature.com/articles/s41586-022-05172-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cebdef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Метод Штрассена и тензорное разложение\n",
    "\n",
    "- Получение формул для алгоритма Штрассена весьма неочевидная задача\n",
    "- Однако их можно получить исходя из общего подхода к задаче вычисления матричного умножения\n",
    "- Этот подход связан с тензорными разложениями\n",
    "- Тензором будем называть многомерный массив – ествественное обобщение матриц\n",
    "\n",
    "Рассмотрим следующую матрицу $2\\times 2$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} c_{1} & c_{3} \\\\ c_{2} & c_{4}  \\end{bmatrix} =\n",
    "\\begin{bmatrix} a_{1} & a_{3} \\\\ a_{2} & a_{4}  \\end{bmatrix}\n",
    "\\begin{bmatrix} b_{1} & b_{3} \\\\ b_{2} & b_{4}  \\end{bmatrix}=\n",
    "\\begin{bmatrix} \n",
    "a_{1}b_{1} + a_{3}b_{2} & a_{1}b_{3} + a_{3}b_{4} \\\\ \n",
    "a_{2}b_{1} + a_{4}b_{2} & a_{2}b_{3} + a_{4}b_{4} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "И заметим, что каждый элемент результата можно записать в следующем виде\n",
    "\n",
    "$$ c_k = \\sum_{i=1}^4 \\sum_{j=1}^4 x_{ijk} a_i b_j, \\quad k=1,2,3,4 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6c4a32",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$x_{ijk}$ – 3-мерный массив, состоящий из 0 и 1:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "x_{\\ :,\\ :,\\ 1} = \n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "\\quad\n",
    "x_{\\ :,\\ :,\\ 2} = \n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "\\end{pmatrix} \\\\\n",
    "x_{\\ :,\\ :,\\ 3} = \n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "\\quad\n",
    "x_{\\ :,\\ :,\\ 4} = \n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{split}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbeb4df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Трилинейное разложение\n",
    "\n",
    "Метод Штрассена можно получить если разложить тензор $x_{ijk}$ следующим образом\n",
    "\n",
    "$$ x_{ijk} = \\sum_{\\alpha=1}^r u_{i\\alpha} v_{j\\alpha} w_{k\\alpha}. $$\n",
    "\n",
    "- Это разложение называется трилинейным тензорным разложением\n",
    "- Интерпретация: разделение переменных (вспомните аналогичную интерпретация SVD!) – сумма $r$ слагаемых, каждое из которых зависит от **одного** индекса результата\n",
    "- Обобщение на тензоры более высокого порядка называется CP-разложением"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8081f55c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Получение метода Штрассена из трилинейного разложения\n",
    "\n",
    "- Подставим общий вид трилинейного разложения\n",
    "\n",
    "$$ c_k = \\sum_{\\alpha=1}^r w_{k\\alpha} \\left(\\sum_{i=1}^4  u_{i\\alpha} a_i \\right) \\left( \\sum_{j=1}^4 v_{j\\alpha} b_j\\right), \\quad k=1,2,3,4. $$\n",
    "\n",
    "- Умножение на $u_{i\\alpha}$, $v_{j\\alpha}$ и $w_{k\\alpha}$ не требует рекурсии, так как это известные факторы трилинейного разложения, которые в результате формируют необходимые комбинации блоков матриц.\n",
    "- Поэтому имеем только $r$ умножения факторов вида $\\left(\\sum_{i=1}^4  u_{i\\alpha} a_i \\right)$ $\\left( \\sum_{j=1}^4 v_{j\\alpha} b_j\\right)$\n",
    " \n",
    "- Если ранг $r$ окажется равным 7, то мы получаем в точности 7 умножений и метод Штрассена"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a60b80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Можно ли лучше?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b7c69c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## AlphaTensor: агент ищет тензорное разложение с помощью обучения с подкреплением\n",
    "\n",
    "- Алгоритм [AlphaTensor](https://www.deepmind.com/blog/discovering-novel-algorithms-with-alphatensor) показал, как подход обучения с подкреплением может помочь в поиске новых тензорных разложений\n",
    "- Состояние в данном случае – это тензор\n",
    "- Действие - вычитание тензора ранга 1\n",
    "- Цель агента – получить нулевой тензор за минимальное количество шагов\n",
    "- За каждый новый шаг получаем награду -1\n",
    "- Отдельная награда даётся, если после $R_{\\max}$ шагов не удалось получить нулевой тензор\n",
    "- Элементы факторов берутся из множества $\\{ \\pm 2, \\pm 1, 0 \\}$\n",
    "\n",
    "<img src=\"alpha_tensor_results.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b5a41d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Выводы про ускорение матричного умножения\n",
    "\n",
    "- Алгоритма за $O(n^2)$ не обнаружено\n",
    "- Алгоритм Штрассена уменьшает асимптотическую сложность наивного метода\n",
    "- Связь поиска эффективного метода матричного умножения и трилинейного тензорного разложения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347fb47",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Переходим к линейным системам и LU разложению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa3306c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Линейные системы\n",
    "\n",
    "$$ Ax = f, $$\n",
    "\n",
    "где матрица $A$ и вектор $f$ известны.\n",
    "\n",
    "Задача решения системы линейных уравнений – одна из основных задач вычислительной линейной алгебры.\n",
    "\n",
    "Она возникает при решении следующих задач:\n",
    "\n",
    "- задача линейной регрессии\n",
    "- решение уравнений в частных производных и интегральных уравнений\n",
    "- задачи нелинейной регрессии\n",
    "- задачи оптимизации (методы Ньютона-Рафсона и Гаусса-Ньютона, условия ККТ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae70bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Пере- и недоопределённые линейные системы\n",
    "\n",
    "Если система $Au = f$ имеет\n",
    "- больше уравнений, чем неизвестных, она называется **переопределённой** (в общем случае не имеет решений)\n",
    "\n",
    "- меньше уравнений, чем неизвестных, она называется **недоопределённой** (решение неединственно, нужны дополнительные предположения, чтобы гарантировать единственность решения)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75f063",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Существование решений \n",
    "\n",
    "Решение системы линейных уравнений с квадратной матрицей $A$\n",
    "\n",
    "$$A u = f$$\n",
    "\n",
    "существует тогда и только тогда, когда \n",
    "* $\\det A \\ne 0$\n",
    "\n",
    "или\n",
    "\n",
    "* матрица $A$ имеет полный ранг."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61177a11",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Шкала размерностей линейных систем \n",
    "\n",
    "В различных приложениях размерности линейных систем могут быть различны \n",
    "\n",
    "- Малая: $n \\leq 10^4$ (вся матрица помещается в память, **плотные матрицы**)\n",
    "- Средняя: $n = 10^4 - 10^6$ (обычно **разреженные** или **структурированные** матрицы)\n",
    "- Большая: $n = 10^8 - 10^9$ (обычно **разреженные** матрицы и параллельные вычисления)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf206956",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Линейные системы могут быть структурированы\n",
    "\n",
    "- Хранение $N^2$ элементов матрицы невозможно уже для $N = 100000$.  \n",
    "\n",
    "**Q:** как работать с такими матрицами?  \n",
    "\n",
    "**A:** к счастью, такие матрицы чаще всего являются **структурированными** и требуют хранения $\\mathcal{O}(N)$ элементов.\n",
    "\n",
    "- Наиболее растространённый тип структурированных матриц – это разреженные матрицы: такие матрицы имеют только $\\mathcal{O}(N)$ ненулевых элементов!  \n",
    "\n",
    "- Пример (одна из самых известных матриц для $n = 5$):\n",
    "\n",
    "$$\n",
    "  \\begin{pmatrix}\n",
    "  2 & -1 & 0 & 0 & 0 \\\\\n",
    "  -1 & 2 & -1 & 0 & 0 \\\\\n",
    "  0 & -1 & 2 & -1 & 0 \\\\\n",
    "  0 & 0 &-1& 2 & -1  \\\\\n",
    "  0 & 0 & 0 & -1 & 2 \\\\\n",
    "  \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "- По крайней мере можно хранить такие матрицы\n",
    "- Также можно умножать такие матрицы на вектор быстро\n",
    "- Но как решать линейные системы с такими матрицами?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a22896",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Основные вопросы о линейных системах\n",
    "\n",
    "1. Какую точность мы можем получить от решения (из-за ошибок округления)?\n",
    "2. Как мы вычислим решение? (LU разложение, метод Гаусса)\n",
    "3. Какая сложность решения системы линейных уравнений?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c2e95",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Как решать линейные системы?\n",
    "\n",
    "**Важно**: забудьте о детерминантах и правиле Крамера (хотя они полезны для матриц $2 \\times 2$)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5c97f22c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.816169839849095e-07\n",
      "1.1053265659484817e-09\n",
      "477 µs ± 101 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "49.6 ms ± 9.59 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bad_cramer(A, b):\n",
    "    det = np.linalg.det(A)\n",
    "    x = np.empty_like(b)\n",
    "    for i in range(b.shape[0]):\n",
    "        cur_col = A[:, i].copy()\n",
    "        A[:, i] = b.copy()\n",
    "        cur_det = np.linalg.det(A)\n",
    "        x[i] = cur_det / det\n",
    "        A[:, i] = cur_col.copy()\n",
    "    return x\n",
    "\n",
    "n = 100\n",
    "A = np.random.randn(n, n)\n",
    "Q, _ = np.linalg.qr(A)\n",
    "eigvals = np.arange(1, n+1, dtype=float)\n",
    "eigvals[-1] = 10000\n",
    "eigvals[0] = 0.0001\n",
    "A = Q @ np.diag(eigvals) @ Q.T\n",
    "b = np.random.randn(n)\n",
    "# print(np.linalg.cond(A))\n",
    "\n",
    "x_good = np.linalg.solve(A, b)\n",
    "x_bad = bad_cramer(A, b)\n",
    "print(np.linalg.norm(A @ x_bad - b) / np.linalg.norm(b))\n",
    "print(np.linalg.norm(A @ x_good - b) / np.linalg.norm(b))\n",
    "%timeit np.linalg.solve(A, b)\n",
    "%timeit bad_cramer(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86782929",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Как решать линейные системы?\n",
    "\n",
    "Основной инструмент – исключение переменных. \n",
    "\n",
    "\\begin{align*}\n",
    "    &2 y + 3 x = 5 &\\longrightarrow \\quad &x = 5/3 -  2/3 y &\\longrightarrow \\quad & x = 5/3 -  2/3 y\\\\\n",
    "    &2 x + 3z = 5 &\\longrightarrow\\quad &2(5/3 -  2/3 y) + 3z = 5 &\\longrightarrow \\quad & y = (-5 + 10/3 + 3z) \\cdot 3/4\\\\\n",
    "    &z + y = 2 &\\longrightarrow\\quad  & z + y = 2, &\\longrightarrow \\quad & (-5 + 10/3 + 3z) \\cdot 3/4 + z = 2\\\\\n",
    "\\end{align*}\n",
    "\n",
    "и так вы можете найти $z$ (и все остальные неизвестные).  \n",
    "\n",
    "Этот процесс называется **методов Гаусса** и является одним из самых часто используемых алгоритмов. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacb3ab7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Метод Гаусса\n",
    "\n",
    "Метод Гаусса состоит из двух этапов:\n",
    "1. Проход вниз\n",
    "2. Проход вверх"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98860c64",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Проход вниз\n",
    "\n",
    "- Исключим $x_1$:\n",
    "\n",
    "$$\n",
    "   x_1 = f_1 - (a_{12} x_2 + \\ldots + a_{1n} x_n)/a_{11},\n",
    "$$\n",
    "\n",
    "и подставим в уравнения $2, \\ldots, n$. \n",
    "\n",
    "- Затем исключим $x_2$ и подставим в остальные уравнения.\n",
    "\n",
    "- Важно, что ведущий элемент (pivot), тот на который мы делим, не равен $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e68d67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Проход вверх\n",
    "\n",
    "Во время прохода назад:\n",
    "- решаем уравнение для $x_n$\n",
    "- подставляем решение в уравнение для $x_{n-1}$ и так далее, пока не вычислим все $x_i, i=1,\\ldots, n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e445cd5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Метод Гаусса и LU разложение\n",
    "\n",
    "Метод Гаусса связан с вычислением одного из самых важных матричных разложений: **LU разложения**.\n",
    "\n",
    "**Определение**: LU разложение матрицы $A$ – это представление\n",
    "\n",
    "$$A =  LU,$$\n",
    "\n",
    "где $L$ – **нижнетреугольная** и $U$ – **верхнетреугольная** матрица.\n",
    "\n",
    "Это разложение **неединственно**, поэтому обычно требуют дополнительно, что на диагонали матрицы $L$ стоят 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91812194",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Обратная матрица: определение\n",
    "\n",
    "Матрица, обратная к матрице $A$, это такая матрица $X$ что  \n",
    "\n",
    "$$\n",
    "   AX = XA = I, \n",
    "$$\n",
    "\n",
    "где $I$ – единичная матрица. Обратная матрица обозначается как $A^{-1}$.\n",
    "\n",
    "Вычисление обратной матрицы связано с решением линейной системы. В самом деле, $i$-ый столбец произведения даёт\n",
    "\n",
    "$$\n",
    "A x_i = e_i,\n",
    "$$\n",
    "\n",
    "где $e_i$ – $i$-ый столбец единичной матрицы. \n",
    "Таким образом, мы можем использовать метод Гаусса, чтобы решить эту систему.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83312313",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Решение системы линейных уравнений после вычисления LU разложения\n",
    "\n",
    "**Основная цель** вычисления LU разложения – это решение системы линейных уравнений, поскольку\n",
    "\n",
    "$$\n",
    "    x^* = A^{-1} f = (L U)^{-1} f = U^{-1} L^{-1} f, \n",
    "$$\n",
    "\n",
    "и задача сводится к решению двух линейных систем с верхне- и нижнетреугольными матрицами.\n",
    "\n",
    "Проход вниз выражается в виде\n",
    "\n",
    "$$\n",
    "     L y = f, \n",
    "$$\n",
    "\n",
    "аналогично для прохода вверх\n",
    "\n",
    "$$\n",
    "   U x = y.\n",
    "$$\n",
    "\n",
    "Всегда ли существует $LU$ разложение?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8739c08f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Существование LU разложения\n",
    "\n",
    "Алгоритм вычисления LU разложения работает, если **мы не делим на $0$** на каждом шаге метода Гаусса.\n",
    "\n",
    "**Q:** Для какого класса матриц это так?\n",
    "\n",
    "**A:** Это так для **строго регулярных матриц**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ec55e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Строго регулярные матрицы и LU разложение\n",
    "\n",
    "**Определение.** Матрица $A$ называется *строго регулярной*, если все лидирующие главные миноры (подматрицы из первых $k$ строк и $k$ столбцов) не вырождены. \n",
    "\n",
    "В этом случае LU разложение всегда существует. Обратное также верно (проверьте!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393777fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LU разложение для положительно определённых Эрмитовых матриц (разложение Холецкого)\n",
    "\n",
    "Строго регулярные матрицы имеют LU разложение. \n",
    "\n",
    "Важный класс строго регулярных матриц – это класс **Эрмитовых положительно определённых матриц**\n",
    "\n",
    "**Определение.** Матрица $A$ называется Эрмитовой положительно определённой, если для любого $x \\in \\mathbb{C}^n: \\Vert x \\Vert \\ne 0$ выполнено\n",
    "\n",
    "$$\n",
    "(x, Ax) > 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1db04",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Утверждение:** Эрмитова положительно определённая матрица $A$ строго регулярна и имеет разложение Холецкого вида\n",
    "\n",
    "$$A = RR^*,$$\n",
    "\n",
    "где $R$ нижнетреугольная матрица.\n",
    "\n",
    "Часто матрица $R$ называется \"квадратным корнем\" матрицы $A$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94756e80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Вычисление LU разложения\n",
    "\n",
    "- Во многих случаях достаточно один раз вычислить LU разложение!\n",
    "\n",
    "- Если такое разложение найдено (что требует $\\mathcal{O}(n^3)$ операций), тогда решение линейной системы сводится к решению линейных систем с матрицами $L$ и $U$, которые требуют $\\mathcal{O}(n^2)$ операций.\n",
    "\n",
    "**Упражнение:** Решение линейной системы с треугольной матрицей вычисляется быстро. Как вычислить $L$ и $U$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d12bd10",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Два способа вычисления LU разложения\n",
    "\n",
    "- Способ 1\n",
    "    - Элементарными преобразованиями $E_i$ приводим матрицу $A$ к верхнетреугольному виду:\n",
    "    \n",
    "    $$ E_n \\ldots E_1 A = U \\quad A = (E_1 \\ldots E_n)^{-1} U = LU$$\n",
    "    \n",
    "    - Так как $E_i$ – нижнетреугольные матрицы, то их произведение и обратная к их произведению матрица также нижнетреугольная, которую можно обозначить $L$\n",
    "\n",
    "- Способ 2 (алгоритм Дулитла)\n",
    "    - Распишем поэлементно равенство $A = LU$\n",
    "    $$ a_{11} = u_{11} \\quad a_{12} = u_{12} \\quad a_{13} = u_{13}$$\n",
    "    \n",
    "    $$ l_{21} = \\frac{a_{21}}{a_{11}} \\quad l_{31} = \\frac{a_{31}}{a_{11}}$$\n",
    "    \n",
    "    $$ u_{22} = \\ldots \\quad u_{23} = \\ldots $$\n",
    "    \n",
    "    - Можно последовательно выразить строки $U$ и столбцы $L$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243bae88",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Сложность метода Гаусса/LU разложения\n",
    "\n",
    "- Каждый шаг исключения занимает $\\mathcal{O}(n^2)$ операций. \n",
    "\n",
    "- Таким образом, сложность алгоритма $\\mathcal{O}(n^3)$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5763aa1a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6816004769691313e-13\n",
      "2.9709118060706874e-14\n",
      "1.96 ms ± 194 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "The slowest run took 10.52 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "4.19 ms ± 5.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "def elementary_lu(A):\n",
    "    n = A.shape[0]\n",
    "    U = A.copy()\n",
    "    L = np.eye(n)\n",
    "    for i in range(n):\n",
    "        el_transform = U[i+1:, i] / U[i, i]\n",
    "        L[i+1:, i] = el_transform\n",
    "        U[i+1:, i:] -= np.outer(L[i+1:, i], U[i, i:])\n",
    "    return L, U\n",
    "\n",
    "def doolittle(A):\n",
    "    n = A.shape[0]\n",
    "    U = np.zeros((n, n))\n",
    "    L = np.eye(n)\n",
    "    for i in range(n):\n",
    "        U[i, i:] = A[i, i:] - L[i, :i] @ U[:i, i:]\n",
    "        L[(i+1):, i] = (A[(i + 1):, i] - L[(i+1):] @ U[:, i]) / U[i, i]\n",
    "    return L, U\n",
    "\n",
    "n = 100\n",
    "A = np.random.randn(n, n)\n",
    "Q, _ = np.linalg.qr(A)\n",
    "eigvals = np.arange(1, n+1, dtype=float)\n",
    "eigvals[-1] = 100\n",
    "eigvals[0] = 1\n",
    "A = Q @ np.diag(eigvals) @ Q.T\n",
    "\n",
    "L_e, U_e = elementary_lu(A)\n",
    "L_d, U_d = doolittle(A)\n",
    "print(np.linalg.norm(A - L_e @ U_e))\n",
    "print(np.linalg.norm(A - L_d @ U_d))\n",
    "\n",
    "%timeit elementary_lu(A)\n",
    "%timeit doolittle(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd6190",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Промежуточный итог\n",
    "\n",
    "- Что такое линйеные системы и какими они бывают\n",
    "- LU разложние и строго регулярные матрицы\n",
    "- Разложение Холецкого как частный случай\n",
    "- Способы вычисления и их сложность"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
